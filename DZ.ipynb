{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daradanci/DeepLearning/blob/main/DZ.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Домашнее задание 1"
      ],
      "metadata": {
        "id": "kaqAxu3neLLw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Импортирование необходимых библиотек"
      ],
      "metadata": {
        "id": "9kd8kA9keZfl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_Tkcu90oGos5"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from glob import glob\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, Dataset, DataLoader\n",
        "from torchsummary import summary\n",
        "from torchvision import transforms as T\n",
        "from tensorflow import summary as tfsummary\n",
        "import pickle\n",
        "from sklearn.metrics import classification_report\n",
        "from PIL import Image\n",
        "from tqdm.auto import tqdm\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "BpgIweY247qa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Чтение тренировочной и тестовой выборки"
      ],
      "metadata": {
        "id": "WXCes5Qxggy-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Инструкция для скачивания и загрузки фотографий в Сolab находится в github"
      ],
      "metadata": {
        "id": "WsGPueHogtRP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Подключаем Google Диск\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Указываем путь к папке с изображениями на Google Диске\n",
        "base_path = '/content/drive/MyDrive/Изображения_ДЗ1_РНС/'\n",
        "\n",
        "heigth_width = 32\n",
        "\n",
        "CLASSES = ['Паук', 'Муравей', 'Скорпион']  # Ваши классы\n",
        "\n",
        "images = []\n",
        "images_t = []\n",
        "classes = []\n",
        "classes_t = []\n",
        "\n",
        "for CLASS in CLASSES:\n",
        "    path_class = os.path.join(base_path, CLASS, '*.*')  # Путь к файлам в папке\n",
        "    image_paths = glob(path_class)\n",
        "    total_images = len(image_paths)\n",
        "    split_index = int(total_images * 0.8)  # 80% для обучения, 20% для теста\n",
        "\n",
        "    for i, photo in enumerate(image_paths):\n",
        "        img = Image.open(photo).convert('RGB')\n",
        "        img = img.resize((heigth_width, heigth_width))\n",
        "\n",
        "        if i >= split_index:\n",
        "            images_t.append(np.asarray(img))\n",
        "            classes_t.append(CLASSES.index(CLASS))\n",
        "        else:\n",
        "            images.append(np.asarray(img))\n",
        "            classes.append(CLASSES.index(CLASS))\n",
        "\n",
        "train_X = np.array(images)\n",
        "train_y = np.array(classes)\n",
        "\n",
        "test_X = np.array(images_t)\n",
        "test_y = np.array(classes_t)\n",
        "\n",
        "print(\"Размер train_X:\", train_X.shape)\n",
        "print(\"Размер train_y:\", train_y.shape)\n",
        "print(\"Размер test_X:\", test_X.shape)\n",
        "print(\"Размер test_y:\", test_y.shape)"
      ],
      "metadata": {
        "id": "3_ZUbtHgWc3v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a522159-b68f-4beb-ad5f-4288b5b4f27a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Размер train_X: (0,)\n",
            "Размер train_y: (0,)\n",
            "Размер test_X: (0,)\n",
            "Размер test_y: (0,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Приведение фотографий к требуемому размеру"
      ],
      "metadata": {
        "id": "o2DLReuahANV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Image.fromarray(train_X[200]).resize((512,512))"
      ],
      "metadata": {
        "id": "SLoDlllvGtXH",
        "outputId": "a70617d6-350e-416a-9c5c-e98a05f9329b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "index 200 is out of bounds for axis 0 with size 0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-de0ae569948c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: index 200 is out of bounds for axis 0 with size 0"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Создание Pytorch DataLoader'a"
      ],
      "metadata": {
        "id": "YuBJ34bmhUR4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CifarDataset(Dataset):\n",
        "     def __init__(self, X, y, transform=None, p=0.0):\n",
        "         assert X.size(0) == y.size(0)\n",
        "         super(Dataset, self).__init__()\n",
        "         self.X = X\n",
        "         self.y = y\n",
        "         self.transform = transform\n",
        "         self.prob = p\n",
        "\n",
        "     def __len__(self):\n",
        "         return self.y.size(0)\n",
        "\n",
        "     def __getitem__(self, index):\n",
        "        x = self.X[index]\n",
        "        if self.transform and np.random.random()<self.prob:\n",
        "            x = self.transform(x.permute(2, 0, 1)/255.).permute(1, 2, 0)*255.\n",
        "        y = self.y[index]\n",
        "        return x, y\n",
        "\n",
        "transform = T.Compose([\n",
        "     T.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.2, hue=0.0),\n",
        "     T.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.8, 1.2),\n",
        "                    shear=5),\n",
        "])\n",
        "\n",
        "Image.fromarray((transform(torch.Tensor(train_X[200]).permute(2, 0, 1)/255.).\\\n",
        "                 permute(1, 2, 0).numpy()*255.).astype(np.uint8)).\\\n",
        "                 resize((256, 256))"
      ],
      "metadata": {
        "id": "MI2qL8NR4EQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 33\n",
        "dataloader = {}\n",
        "for (X, y), part in zip([(train_X, train_y), (test_X, test_y)],\n",
        "                        ['train', 'test']):\n",
        "    tensor_x = torch.Tensor(X)\n",
        "    tensor_y = F.one_hot(torch.Tensor(y).to(torch.int64),\n",
        "                                     num_classes=len(CLASSES))/1.\n",
        "    dataset = CifarDataset(tensor_x, tensor_y,\n",
        "                           transform if part=='train' else None,\n",
        "                           p=0.5) # создание объекта датасета\n",
        "    dataloader[part] = DataLoader(dataset, batch_size=batch_size,\n",
        "                                  prefetch_factor=8 if part=='train' else 2,\n",
        "                                  num_workers=2, persistent_workers=True,\n",
        "                                  shuffle=True) # создание экземпляра класса DataLoader\n",
        "dataloader"
      ],
      "metadata": {
        "id": "hJckmOPk4KFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# batch_size = 33\n",
        "# dataloader = {}\n",
        "# for (X, y), part in zip([(train_X, train_y), (test_X, test_y)],\n",
        "#                         ['train', 'test']):\n",
        "#     tensor_x = torch.Tensor(X)\n",
        "#     tensor_y = F.one_hot(torch.Tensor(y).to(torch.int64),\n",
        "#                                      num_classes=len(CLASSES))/1.\n",
        "#     dataset = TensorDataset(tensor_x, tensor_y) # создание объекта датасета\n",
        "#     dataloader[part] = DataLoader(dataset, batch_size=batch_size, shuffle=True) # создание экземпляра класса DataLoader\n",
        "# dataloader"
      ],
      "metadata": {
        "id": "dnVQ5m0kY2Cc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Создание Pytorch модели"
      ],
      "metadata": {
        "id": "OXG8kHNjhfuO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Normalize(nn.Module):\n",
        "    def __init__(self, mean, std):\n",
        "        super(Normalize, self).__init__()\n",
        "        self.mean = torch.tensor(mean).to(device)\n",
        "        self.std = torch.tensor(std).to(device)\n",
        "\n",
        "    def forward(self, input):\n",
        "        x = input / 255.0\n",
        "        x = x - self.mean\n",
        "        x = x / self.std\n",
        "        return x.permute(0, 3, 1, 2) # nhwc -> nm\n",
        "\n",
        "class GlobalMaxPool2d(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GlobalMaxPool2d, self).__init__()\n",
        "\n",
        "    def forward(self, input):\n",
        "        out = F.adaptive_max_pool2d(input, output_size=1)\n",
        "        return out.flatten(start_dim=1)\n",
        "\n",
        "class Cifar100_MLP(nn.Module):\n",
        "    def __init__(self, hidden_size=32, classes=100):\n",
        "        super(Cifar100_MLP, self).__init__()\n",
        "        # https://blog.jovian.ai/image-classification-of-cifar100-dataset-using-pytorch-8b7145242df1\n",
        "        self.seq = nn.Sequential(\n",
        "            Normalize([0.5074,0.4867,0.4411],[0.2011,0.1987,0.2025]),\n",
        "            # первый способ уменьшения размерности картинки - через stride\n",
        "            nn.Conv2d(3, HIDDEN_SIZE, 5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(4),\n",
        "            nn.Dropout2d(p=0.1),\n",
        "            # второй способ уменьшения размерности картинки - через слой пуллинг\n",
        "            nn.Conv2d(HIDDEN_SIZE, HIDDEN_SIZE*2, 3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.AvgPool2d(4),\n",
        "            nn.Dropout2d(p=0.2),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(HIDDEN_SIZE*8, classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.seq(input)\n",
        "\n",
        "model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\",\n",
        "                       #\"cifar100_mobilenetv2_x0_5\",\n",
        "                       'cifar100_resnet20',\n",
        "                       pretrained=True)\n",
        "model.to(device)\n",
        "new_model = nn.Sequential(\n",
        "    Normalize([0.5074,0.4867,0.4411],[0.2011,0.1987,0.2025]),# https://blog.jovian.ai/image-classification-of-cifar100-dataset-using-pytorch-8b7145242df1\n",
        "    model\n",
        ").to(device)\n",
        "print(new_model(torch.rand(1, 32, 32, 3).to(device)))\n",
        "summary(new_model, input_size=(32, 32, 3))\n",
        "new_model"
      ],
      "metadata": {
        "id": "Dtld1amNY9lT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## resnet20\n",
        "in_features = new_model[1].fc.in_features\n",
        "new_model[1].fc = nn.Linear(in_features=in_features,\n",
        "                            out_features=len(CLASSES),\n",
        "                            bias=True)\n",
        "\n",
        "new_model.to(device)\n",
        "summary(new_model, input_size=(32, 32, 3))\n",
        "print(new_model(torch.rand(1, 32, 32, 3).to(device)))"
      ],
      "metadata": {
        "id": "ha4UoT-l5PzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Заморозка весов и обучение модели"
      ],
      "metadata": {
        "id": "OarOMdpe6ksy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Обучаемые параметры:\")\n",
        "keep_last = 74\n",
        "total = len([*new_model.named_parameters()])\n",
        "params_to_update = []\n",
        "for i, (name, param) in enumerate(new_model.named_parameters()):\n",
        "    if i < total - keep_last:\n",
        "        param.requires_grad = False\n",
        "    else:\n",
        "        params_to_update.append(param)\n",
        "        param.requires_grad = True\n",
        "        print(\"\\t\",name)\n",
        "summary(new_model, input_size=(32, 32, 3))"
      ],
      "metadata": {
        "id": "7OG8wH075kpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# добавляем сглаживание целевых меток, это увеличит значение функции потерь\n",
        "# но полученная модель будет более устойчивой к выбросам в обучающей выборке\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "# используется SGD c momentum и L2-регуляризацией весов\n",
        "optimizer = optim.SGD(params_to_update, lr=3e-4, momentum=0.9,\n",
        "                      weight_decay=1e-4)\n",
        "# добавляем постепенное уменьшение шага обучения каждые 20 эпох\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)"
      ],
      "metadata": {
        "id": "L8CeljfX6J5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 30\n",
        "REDRAW_EVERY = 10\n",
        "steps_per_epoch = len(dataloader['train'])\n",
        "steps_per_epoch_val = len(dataloader['test'])\n",
        "# NEW\n",
        "pbar = tqdm(total=EPOCHS*steps_per_epoch)\n",
        "losses = []\n",
        "losses_val = []\n",
        "passed = 0\n",
        "# для создания чекпоинта\n",
        "best_acc = 0\n",
        "checkpoint_path = 'cifar_cnn_fine.pth'\n",
        "for epoch in range(EPOCHS):  # проход по набору данных несколько раз\n",
        "    tmp = []\n",
        "    new_model.train()\n",
        "    for i, batch in enumerate(dataloader['train'], 0):\n",
        "        # получение одного минибатча; batch это двуэлементный список из [inputs, labels]\n",
        "        inputs, labels = batch\n",
        "        # на GPU\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # очищение прошлых градиентов с прошлой итерации\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # прямой + обратный проходы + оптимизация\n",
        "        outputs = new_model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        #loss = F.cross_entropy(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # для подсчёта статистик\n",
        "        accuracy = (labels.detach().argmax(dim=-1)==outputs.detach().argmax(dim=-1)).\\\n",
        "                    to(torch.float32).mean().cpu()*100\n",
        "        tmp.append((loss.item(), accuracy.item()))\n",
        "        pbar.update(1)\n",
        "    losses.append((np.mean(tmp, axis=0),\n",
        "                   np.percentile(tmp, 25, axis=0),\n",
        "                   np.percentile(tmp, 75, axis=0)))\n",
        "    scheduler.step() # обновляем learning_rate каждую эпоху\n",
        "    tmp = []\n",
        "    new_model.eval()\n",
        "    with torch.no_grad(): # отключение автоматического дифференцирования\n",
        "        for i, data in enumerate(dataloader['test'], 0):\n",
        "            inputs, labels = data\n",
        "            # на GPU\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = new_model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            accuracy = (labels.argmax(dim=-1)==outputs.argmax(dim=-1)).\\\n",
        "                        to(torch.float32).mean().cpu()*100\n",
        "            tmp.append((loss.item(), accuracy.item()))\n",
        "    losses_val.append((np.mean(tmp, axis=0),\n",
        "                       np.percentile(tmp, 25, axis=0),\n",
        "                       np.percentile(tmp, 75, axis=0)))\n",
        "    # сохранение чекпоинта\n",
        "    acc = losses_val[-1][0][1]\n",
        "    if acc > best_acc:\n",
        "        best_acc = acc\n",
        "        torch.save(new_model.state_dict(), checkpoint_path)\n",
        "    # обновление графиков\n",
        "    if (epoch+1) % REDRAW_EVERY != 0:\n",
        "        continue\n",
        "    clear_output(wait=False)\n",
        "    print('Эпоха: %s\\n'\n",
        "          'Лучшая доля правильных ответов: %s\\n'\n",
        "          'Текущая доля правильных ответов: %s' % (epoch+1, best_acc, acc))\n",
        "    passed += pbar.format_dict['elapsed']\n",
        "    pbar = tqdm(total=EPOCHS*steps_per_epoch, miniters=5)\n",
        "    pbar.update((epoch+1)*steps_per_epoch)\n",
        "    x_vals = np.arange(epoch+1)\n",
        "    _, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
        "    stats = np.array(losses)\n",
        "    stats_val = np.array(losses_val)\n",
        "    ax[1].set_ylim(stats_val[:, 0, 1].min()-5, 100)\n",
        "    ax[1].grid(axis='y')\n",
        "    for i, title in enumerate(['CCE', 'Accuracy']):\n",
        "        ax[i].plot(x_vals, stats[:, 0, i], label='train')\n",
        "        ax[i].fill_between(x_vals, stats[:, 1, i],\n",
        "                           stats[:, 2, i], alpha=0.4)\n",
        "        ax[i].plot(x_vals, stats_val[:, 0, i], label='val')\n",
        "        ax[i].fill_between(x_vals,\n",
        "                           stats_val[:, 1, i],\n",
        "                           stats_val[:, 2, i], alpha=0.4)\n",
        "        ax[i].legend()\n",
        "        ax[i].set_title(title)\n",
        "    plt.show()\n",
        "new_model.load_state_dict(torch.load(checkpoint_path))\n",
        "print('Обучение закончено за %s секунд' % passed)"
      ],
      "metadata": {
        "id": "KHxQkk316L_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Проверка качества модели по классам на обучающей и тестовой выборках"
      ],
      "metadata": {
        "id": "wN27qGDPhwux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 33\n",
        "dataloader = {}\n",
        "for (X, y), part in zip([(train_X, train_y), (test_X, test_y)],\n",
        "                        ['train', 'test']):\n",
        "    tensor_x = torch.Tensor(X)\n",
        "    tensor_y = F.one_hot(torch.Tensor(y).to(torch.int64),\n",
        "                                     num_classes=len(CLASSES))/1.\n",
        "    dataset = CifarDataset(tensor_x, tensor_y,\n",
        "                           transform=None,\n",
        "                           p=0.0) # создание объекта датасета\n",
        "    dataloader[part] = DataLoader(dataset, batch_size=batch_size,\n",
        "                                  num_workers=2, shuffle=True) # создание экземпляра класса DataLoader\n",
        "dataloader"
      ],
      "metadata": {
        "id": "TQoToFaf6a6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for part in ['train', 'test']:\n",
        "    y_pred = []\n",
        "    y_true = []\n",
        "    with torch.no_grad(): # отключение автоматического дифференцирования\n",
        "        for i, data in enumerate(dataloader[part], 0):\n",
        "            inputs, labels = data\n",
        "             # на GPU\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = new_model(inputs).detach().cpu().numpy()\n",
        "            y_pred.append(outputs)\n",
        "            y_true.append(labels.cpu().numpy())\n",
        "        y_true = np.concatenate(y_true)\n",
        "        y_pred = np.concatenate(y_pred)\n",
        "        print(part)\n",
        "        print(classification_report(y_true.argmax(axis=-1), y_pred.argmax(axis=-1),\n",
        "                                    digits=4, target_names=list(map(str, CLASSES))))\n",
        "        print('-'*50)"
      ],
      "metadata": {
        "id": "k7OkUQAlZMua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Сохранение модели в ONNX"
      ],
      "metadata": {
        "id": "gGv5L6lMiMP-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# сохраниение модели\n",
        "# ПЕРВЫЙ СПОСОБ: сохранение параметров\n",
        "PATH = 'cifar.pth'\n",
        "torch.save(model.state_dict(), PATH)\n",
        "# загрузка\n",
        "new_model = Cifar100_MLP(hidden_size=HIDDEN_SIZE, classes=len(CLASSES))\n",
        "new_model.load_state_dict(torch.load(PATH))\n",
        "new_model.eval()\n",
        "\n",
        "# ВТОРОЙ СПОСОБ: сохранение всей архитектуры\n",
        "PATH2 = 'cifar.pt'\n",
        "torch.save(model, PATH2)\n",
        "# загрузка\n",
        "new_model_2 = torch.load(PATH2)\n",
        "new_model_2.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvWbYlrxZpG3",
        "outputId": "f22f6e11-9511-49a8-c82f-4aeaa5e051af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Cifar100_MLP(\n",
              "  (norm): Normalize()\n",
              "  (seq): Sequential(\n",
              "    (0): Linear(in_features=3072, out_features=10, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=10, out_features=3, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# входной тензор для модели\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "x = torch.randn(1, 32, 32, 3, requires_grad=True).to(device)\n",
        "torch_out = model(x)\n",
        "\n",
        "# экспорт модели\n",
        "torch.onnx.export(model,               # модель\n",
        "                  x,                   # входной тензор (или кортеж нескольких тензоров)\n",
        "                  \"cifar100.onnx\", # куда сохранить (либо путь к файлу либо fileObject)\n",
        "                  export_params=True,  # сохраняет веса обученных параметров внутри файла модели\n",
        "                  opset_version=9,     # версия ONNX\n",
        "                  do_constant_folding=True,  # следует ли выполнять укорачивание констант для оптимизации\n",
        "                  input_names = ['input'],   # имя входного слоя\n",
        "                  output_names = ['output'],  # имя выходного слоя\n",
        "                  dynamic_axes={'input' : {0 : 'batch_size'},    # динамичные оси, в данном случае только размер пакета\n",
        "                                'output' : {0 : 'batch_size'}})"
      ],
      "metadata": {
        "id": "3ZWLRj21Zq44"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}